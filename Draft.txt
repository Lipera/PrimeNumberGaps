Motivation
Prime numbers have been a mystery for centuries. Recently a new pattern was discovered among them, which was shown to be related to the distribution of the differences between consecutive primes. These differences are called "prime gaps". The paper by Robert J. Lemke Oliver and Kannan Soundararajan shows that the pattern is related to the Hardy-Littlewood conjecture, from 1923, which gives an approximation to that distribution.

Generation
To work with very large integers, which is necessary to provide significance to sublinear factors such as log(n), we used the GNU Multiple Precision library with the C language. This library is very popular, being used by Python, for example, to provide integers with arbitrary magnitude.
The library already implements the Miller-Rabin probabilistic primality test, and uses it for a function called "nextprime", which computes the smallest prime larger than a given input. By altering this function slightly, we can also compute the "previous prime", and the difference between these two primes is the prime gap surrounding the input.
There is an issue with generating prime gaps by this approach: the (Bus) Waiting Paradox. This so-called paradox is mostly known from Poisson distributions, but affects any other if the sampling approach is similar. It is seemingly contradiction that, if buses arrive in a Poisson distribution, if the average time between buses is 15 minutes, then the average time you must wait in a bus stop is also 15 minutes, regardless of how long ago the previous bus left. The contradiction is that the average time since the last bus is also 15 minutes, meaning you observe an average gap of 30 minutes. This is explained by the fact that it is more probable to arrive at the bus stop during a long gap, there is a bias towards them: if one gap is 10 minutes long and another 20, the average gap is 15 minutes, however the average observed gap is 16 minutes and 40 seconds, since it is more probable to arrive during the longer gap.
We solve this problem during generation, by adding an extra step to it: if a gap of size 2k was found, it is accepted only with 1/k probability. That is due to the fact that each gap of size 2k has 2k possibilities of being picked, so adding an inversely proportional weight to that corrects the bias.
The bias could also be solved by considering that factor as an importance weight, where a weight of 2 would mean the same as having a second identical observation. However, altering the generation was much simpler for us, and does not significantly impact the amount of data generated: the GMP library and C language are very fast, originally outputting thousands of samples each second, so rejecting a portion of them does not impact the significance of our analysis.
Note that doing this changes the probability distribution of the input: as we could see with the rest of our work, larger numbers have larger gaps. This means that weighting larger gaps down, or rejecting them randomly as we are doing, means weighting down larger inputs more than smaller ones. Thus it is very important to keep this bias in mind, as now the number of samples is proportional to the number of gaps, not the size of the input.
We also generate the next gap, in order to test one of our hypothesis.
As for the way of generating the inputs, we use the GMP library functions for generating uniformly random numbers. We did, however, want to generate numbers in a logarithmic scale, in order to be able to notice the impact of sublinear factors. This generation could be done by first generating a uniformly random real number and then using it as exponent to a fixed base, however with very large numbers it is hard to do so due to precision concerns. What we do, then, is to generate an integer exponent n instead, which gives a range of possible numbers, from 2^n to 2^(n+1). We have that the probability of choosing a number x is proportional to log(x)-log(x-1) ~ 1/x, so we generate a uniformly random number in that range and accept it with 2^n/x chance.

Hypothesis
Since prime numbers are a very popular topic in pure mathematics, there are many theorems and conjectures involving them. The most important theorem for this work is the Prime Number Theorem: it says that the number of primes up to x, pi(x), tends to x/ln(x), for x large enough. Note that this number is also the number of prime gaps up to x, since each prime is followed by exactly one prime gap.
Also very important for this work is the Hardy-Littlewood conjecture, also called the k-tuples conjecture. It gives an estimation to the amount of prime constellations up to a number x. In particular, it says the amount of gaps of size 2k tends to C(k) * \int_2^x 1/ln²(t) dt.
We thus formulated some hypothesis based on those two formulas:
* The Prime Number Theorem says that, over time, the freauency of prime numbers becomes lower. That would mean that the average prime gap becomes larger with a larger input.
* More specifically, if we have a prime gap from a to b, we have that pi(b)-pi(a)=1 and b-a=gap, so (pi(b)-pi(a))/(b-a) = 1/gap. The left side of that equation can be seen as similar to the derivative of pi(x). Since the Prime Number Theorem gives the approximation pi(x) ~ x/ln(x), we have that 1/gap ~ 1/ln(x) - 1/ln²(x).
  But what is this 1/gap? It is the average of 1/gap with the Waiting Paradox bias, or 1/the average of gap with the bias correction. The first one is since considering 1/gap for each possible input between a and b, we get sum equal to the number of gaps between a and b, however since it is for each input we get more samples from larger gaps. The second one is due to that considering the gaps between a and b, the sum of their lengths is b-a, and so their average is (b-a)/(pi(b)-pi(a)).
  That is, for inputs close to x, the average of the gaps should be approximately 1/(1/ln(x) - 1/ln²(x)) = ln²(x)/(ln(x)-1) ~ ln(x).
* We can similarly make the hypothesis that other statistical measures, such as the median and quantiles, also scale proportionally to ln(x).
* The Lemke Oliver and Soundarajan observation is that consecutive prime numbers have some correlation, so we decided to investigate if consecutive prime gaps are too. Our initial hypothesis is that there is not, since they are regarded as being very "random".
* Derivating the Hardy-Littlewood formula, we get that the probability of a gap of size 2k is proportional to C(k)/ln²x. One hypothesis we can look into is that this is true, since the mathematical community strongly believes in the conjecture.
* We can also go beyond checking the average number of gaps of a given size, we can ask if they also behave randomly. One hypothesis is that they follow a Poisson distribution.

https://gmplib.org/
https://arxiv.org/abs/1603.03720
Hardy, G. H. and Littlewood, J. E. "Some Problems of 'Partitio Numerorum.' III. On the Expression of a Number as a Sum of Primes." Acta Math. 44, 1-70, 1923.
