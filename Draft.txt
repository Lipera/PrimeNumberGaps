Motivation
Prime numbers have been a mystery for centuries. Recently a new pattern was discovered among them, which was shown to be related to the distribution of the differences between consecutive primes. These differences are called "prime gaps". The paper by Robert J. Lemke Oliver and Kannan Soundararajan shows that the pattern is related to the Hardy-Littlewood conjecture, from 1923, which gives an approximation to that distribution.

Generation
To work with very large integers, which is necessary to provide significance to sublinear factors such as log(n), we used the GNU Multiple Precision library with the C language. This library is very popular, being used by Python, for example, to provide integers with arbitrary magnitude.
The library already implements the Miller-Rabin probabilistic primality test, and uses it for a function called "nextprime", which computes the smallest prime larger than a given input. By altering this function slightly, we can also compute the "previous prime", and the difference between these two primes is the prime gap surrounding the input.
There is an issue with generating prime gaps by this approach: the (Bus) Waiting Paradox. This so-called paradox is mostly known from Poisson distributions, but affects any other if the sampling approach is similar. It is seemingly contradiction that, if buses arrive in a Poisson distribution, if the average time between buses is 15 minutes, then the average time you must wait in a bus stop is also 15 minutes, regardless of how long ago the previous bus left. The contradiction is that the average time since the last bus is also 15 minutes, meaning you observe an average gap of 30 minutes. This is explained by the fact that it is more probable to arrive at the bus stop during a long gap, there is a bias towards them: if one gap is 10 minutes long and another 20, the average gap is 15 minutes, however the average observed gap is 16 minutes and 40 seconds, since it is more probable to arrive during the longer gap.
We solve this problem during generation, by adding an extra step to it: if a gap of size 2k was found, it is accepted only with 1/k probability. That is due to the fact that each gap of size 2k has 2k possibilities of being picked, so adding an inversely proportional weight to that corrects the bias.
The bias could also be solved by considering that factor as an importance weight, where a weight of 2 would mean the same as having a second identical observation. However, altering the generation was much simpler for us, and doesn't significantly impact the amount of data generated: the GMP library and C language are very fast, originally outputting thousands of samples each second, so rejecting a portion of them doesn't impact the significance of our analysis.
We also generate the next gap, in order to test one of our hypothesis.
As for the way of generating the inputs, we use the GMP library functions for generating uniformly random numbers. We did, however, want to generate numbers in a logarithmic scale, in order to be able to notice the impact of sublinear factors. This generation could be done by first generating a uniformly random real number and then using it as exponent to a fixed base, however with very large numbers it's hard to do so due to precision concerns. What we do, then, is to generate an integer exponent n instead, which gives a range of possible numbers, from 2^n to 2^(n+1). We have that the probability of choosing a number x is proportional to log(x)-log(x-1) ~ 1/x, so we generate a uniformly random number in that range and accept it with 2^n/x chance.

Validation
If we have a prime gap from a to b, we have that pi(b)-pi(a)=1, and thus (pi(b)-pi(a))/(b-a) = 1/gap. The left side of that equation can be seen as similar to the derivative of pi(x). Since the Prime Number Theorem gives the approximation pi(x) ~ x/ln(x), we have that 1/gap ~ 1/ln(x) - 1/lnÂ²(x), so we can initially validate our data with that.
But what is this 1/gap? It is the average of 1/gap with the Waiting Paradox bias, or 1/the average of gap with the bias correction. The first one is since considering 1/gap for each possible input between a and b, we get sum equal to the number of gaps between a and b, however since it's for each input we get more samples from larger gaps. The second one is due to that considering the gaps between a and b, the sum of their lengths is b-a, and so their average is (b-a)/(pi(b)-pi(a)).

Bibliography
https://arxiv.org/abs/1603.03720
Hardy, G. H. and Littlewood, J. E. "Some Problems of 'Partitio Numerorum.' III. On the Expression of a Number as a Sum of Primes." Acta Math. 44, 1-70, 1923.
