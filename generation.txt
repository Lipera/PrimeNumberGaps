Generation: 

In this project we worked with very large integers. This is
necessary to provide significance to sublinear factors - factor smaller than n,
such as log(n).  To generate large integers we used the very popular GNU
Multiple Precision library (GMP) with the C language. This library is used by
Python, for example, to provide integers with arbitrary magnitude.  The library
implements the Miller-Rabin probabilistic primality test. It uses it for a
function called 'nextprime', that computes the smallest prime larger than the
given input. By altering this function we can compute the 'previous prime'. The
difference between these two primes is the prime gap surrounding the input. For
example, if we take an input of value 4, we know that the previous prime of 4
is 3 and the next prime is 5. The difference (i.e. prime gap) between 3 and 5
is 2. This gap of 2 is surrounding the input of 4.

Generating prime gaps in this way can have the issue of the (Bus) Waiting
Paradox. This so-called paradox is mostly known from Poisson distributions, but
may affect any other distribution if the sampling approach is similar.  It
seems contradictory that if buses arrive in a Poisson distribution and the
average time between them is 15 minutes, then the average time you must wait in
a bus stop is also 15 minutes, regardless of how long ago the previous bus
left. The contradiction is that the average time since the last bus is also 15
minutes. This means you observe an average gap of 30 minutes. This is explained
by the fact that it is more probable to arrive at the bus stop during a long
gap. This is a bias approach towards longer gaps. As an example, if one gap is
10 minutes long and another is 20 then the average gap is 15 minutes.  However
the average observed gap is 16 minutes and 40 seconds, since it is more
probable for an observer to arrive during the longer gap. 

We solve this problem during generation by adding an extra step to it. In this
step, if a gap is found with size of 2k then it is accepted only with 1/k
probability. This is because each gap of size 2k has 2k possibilities of
getting selected. By adding an inversely proportional weight to it, we correct
this bias.  This bias could also be solved by considering that the factor has
an importance weight, where a weight of 2 would mean the same as having a
second identical observation. However, altering the generation was much simpler
for us, and doesn't significantly impact the amount of time needed to generate
the data. The GMP library and C language are very fast, originally outputting
thousands of samples each second, so rejecting a portion doesn't impact the
significance of our analysis. Note that doing this changes the probability
distribution of the input, since, as we could see with the rest of our work,
larger inputs have larger gaps. This means that weighting larger gaps down, or
rejecting them randomly, means weighting down larger inputs more than smaller
ones. Thus it is very important to keep this bias in mind, as now the number of
samples is proportional to the number of gaps, not the size of the input.  We
also generate the next gap, to test the hypothesis that there is no correlation
between consecutive prime gaps.  To generate uniform random numbers for inputs
we use the GMP library functions. We focused on generating input numbers in a
logarithmic scale. This is to be able to notice the impact of sublinear
factors. The generation could be done by first generating a uniformly random
real number and then using it as exponent to a fixed base.  However, with very
large numbers this is hard to do due to concerns of precision.  We instead
generate an integer exponent n, which gives a range of possible numbers, from
2^n to 2^(n+1). We have that the probability of choosing a number x should be
proportional to log(x)-log(x-1) ~ 1/x, so we generate a uniformly random number
in that range and accept it with 2^n/x chance.


